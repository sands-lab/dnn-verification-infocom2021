{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analyzing Learning-Based Networked Systems with Formal Verification\n",
    "\n",
    "## Experiments and examples\n",
    "\n",
    "This notebook contains the code used to collect the results shown in section 6 of our paper. To run this notebook, make sure to have installed the requirements as indicated in the README for the selected kernel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "import time\n",
    "import numpy as np\n",
    "\n",
    "from collections import OrderedDict, defaultdict\n",
    "from matplotlib import pyplot as plt\n",
    "from pprint import pprint\n",
    "\n",
    "\n",
    "import pensieve"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment 1: Resilience to adversarial perturbations\n",
    "\n",
    "This experiment aims to test how resilient Pensieve is to changes in the inputs. The returned value is $\\epsilon$, the attacker power (proportional to the full range of attacked inputs). Two cases are tested: one with constant throughput, and one with an actual trace taken from the Pensieve dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implementation\n",
    "\n",
    "This experiment is implemented by searching for bounds on $\\epsilon$ such that the attacker cannot change the output with the lower bound, but can change it with the higher bound.\n",
    "\n",
    "The result of the experiments is written to the file `test_resilience_pensieve_caseX`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_to_closest(value, options):\n",
    "    dist = float('inf')\n",
    "    selected = None\n",
    "    for option in options:\n",
    "        if abs(value - option) < dist:\n",
    "            selected = option\n",
    "            dist = abs(option - value)\n",
    "    return selected\n",
    "\n",
    "\n",
    "def test_perturbation(default_values, expected_br, delta, epsilon, discrete_inputs):\n",
    "    # returns true if the perturbation does not cause a violation\n",
    "    bounds = dict()\n",
    "    \n",
    "    for var in default_values:\n",
    "        lb = default_values[var] - delta[var]*epsilon\n",
    "        ub = default_values[var] + delta[var]*epsilon\n",
    "        \n",
    "        if var in discrete_inputs:\n",
    "            lb = map_to_closest(lb, discrete_inputs[var])\n",
    "            ub = map_to_closest(ub, discrete_inputs[var])\n",
    "            \n",
    "        bounds[var] = (lb, ub)\n",
    "    \n",
    "    # Encoding of the network\n",
    "    exp = pensieve.PropertyExplainer()\n",
    "    exp.encode_input_layers()\n",
    "    exp.encode_hidden_layers()\n",
    "    \n",
    "    for var in bounds:\n",
    "        lb, ub = bounds[var]\n",
    "        exp.encode_tighter_bounds(var, lb, ub)\n",
    "        \n",
    "    exp.encode_expected_output(expected_br, inverted=True)\n",
    "    \n",
    "    exp.find_solutions(stop_after_one=True)\n",
    "    \n",
    "    return len(exp.solutions) == 0\n",
    "\n",
    "\n",
    "def search_perturbation_resilience(initial_values,\n",
    "                                   expected_output,\n",
    "                                   scaled_deltas,\n",
    "                                   discrete_inputs,\n",
    "                                   precision=0.001):\n",
    "    epsilon = 0\n",
    "    # check that we actually match expected output with epsilon == 0\n",
    "    if not test_perturbation(initial_values, expected_output, scaled_deltas, 0, discrete_inputs):\n",
    "        print('Error: initial values do not match expected output')\n",
    "        return 0\n",
    "    \n",
    "    epsilon = 0.01\n",
    "    low_bound = 0\n",
    "    high_bound = None\n",
    "    start_time = time.time()\n",
    "    # multiplicative increase search for bounds\n",
    "    while test_perturbation(initial_values, expected_output, scaled_deltas, epsilon, discrete_inputs):\n",
    "        low_bound = epsilon\n",
    "        epsilon *= 1.3\n",
    "        print(f'searching bounds (epsilon = {epsilon})')\n",
    "    high_bound = epsilon\n",
    "    print(f'found bounds: ({low_bound}, {high_bound})')\n",
    "    \n",
    "    # binary search for exact value in (low_bound, high_bound)\n",
    "    while high_bound - low_bound > precision:\n",
    "        epsilon = (high_bound + low_bound) / 2\n",
    "        if test_perturbation(initial_values, expected_output, scaled_deltas, epsilon, discrete_inputs):\n",
    "            low_bound = epsilon\n",
    "        else:\n",
    "            high_bound = epsilon \n",
    "        print(f'refined bounds: ({low_bound}, {high_bound})')\n",
    "        \n",
    "    end_time = time.time()\n",
    "    print('Run time:', round(end_time - start_time, 3), 'seconds')\n",
    "            \n",
    "    return epsilon"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Case 1: Constant throughput of 1850Kbps\n",
    "\n",
    "The values below represent the default input being tested in case 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "default_values = {\n",
    "    'x_prev_bitrate_0$': 1850/4300, # expect 1850 Kbps\n",
    "    'x_buffer_0$': 1.573854,\n",
    "    'x_throughput_0$': 0.23125, # fixed 1850 Kbps goodput\n",
    "    'x_throughput_1$': 0.23125,\n",
    "    'x_throughput_2$': 0.23125,\n",
    "    'x_throughput_3$': 0.23125,\n",
    "    'x_throughput_4$': 0.23125,\n",
    "    'x_throughput_5$': 0.23125,\n",
    "    'x_throughput_6$': 0.23125,\n",
    "    'x_throughput_7$': 0.23125,\n",
    "    'x_latency_0$': 0.504, # next_size_3 / throughput / 8\n",
    "    'x_latency_1$': 0.504,\n",
    "    'x_latency_2$': 0.504,\n",
    "    'x_latency_3$': 0.504,\n",
    "    'x_latency_4$': 0.504,\n",
    "    'x_latency_5$': 0.504,\n",
    "    'x_latency_6$': 0.504,\n",
    "    'x_latency_7$': 0.504,\n",
    "    'x_next_size_0$': 0.153233,\n",
    "    'x_next_size_1$': 0.380457,\n",
    "    'x_next_size_2$': 0.605353,\n",
    "    'x_next_size_3$': 0.931950,\n",
    "    'x_next_size_4$': 1.437556,\n",
    "    'x_next_size_5$': 2.158495,\n",
    "    'x_remaining_chunks_0$': 24/48,\n",
    "}\n",
    "\n",
    "bounds = {\n",
    "    'x_prev_bitrate_0$': (300/4300, 4300/4300),\n",
    "    'x_buffer_0$': (0.4, 3.267816),\n",
    "    'x_throughput_0$': (0, 0.541045),\n",
    "    'x_throughput_1$': (0, 0.541045),\n",
    "    'x_throughput_2$': (0, 0.541045),\n",
    "    'x_throughput_3$': (0, 0.541045),\n",
    "    'x_throughput_4$': (0, 0.541045),\n",
    "    'x_throughput_5$': (0, 0.542024),\n",
    "    'x_throughput_6$': (0, 0.542086),\n",
    "    'x_throughput_7$': (0.069767, 0.542258),\n",
    "    'x_latency_0$': (0, 1.210133),\n",
    "    'x_latency_1$': (0, 1.226670),\n",
    "    'x_latency_2$': (0, 1.226670),\n",
    "    'x_latency_3$': (0, 1.253752),\n",
    "    'x_latency_4$': (0, 1.257164),\n",
    "    'x_latency_5$': (0, 1.259484),\n",
    "    'x_latency_6$': (0, 1.259484),\n",
    "    'x_latency_7$': (0.083082, 1.259484),\n",
    "    'x_next_size_0$': (0.111155, 0.181901),\n",
    "    'x_next_size_1$': (0.277716, 0.450283),\n",
    "    'x_next_size_2$': (0.487160, 0.709534),\n",
    "    'x_next_size_3$': (0.728962, 1.076598),\n",
    "    'x_next_size_4$': (1.139290, 1.728878),\n",
    "    'x_next_size_5$': (1.919781, 2.395588),\n",
    "    'x_remaining_chunks_0$': (0, 1),\n",
    "}\n",
    "\n",
    "discrete_inputs = {\n",
    "    'x_prev_bitrate_0$': [v / 4300 for v in [300, 750, 1200, 1850, 2850, 4300]],\n",
    "    'x_remaining_chunks_0$': [v / 48 for v in range(48)],\n",
    "}\n",
    "\n",
    "result_file = 'test_resilience_pensieve_case1'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experiment 1: attacker controls all features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the full range of all variables that the attacker controls\n",
    "delta = {k: bounds[k][1] - bounds[k][0] for k in bounds}\n",
    "\n",
    "pprint(delta)\n",
    "\n",
    "# Compute the value of epsilon\n",
    "resilience = search_perturbation_resilience(default_values,\n",
    "                                            3,\n",
    "                                            delta,\n",
    "                                            discrete_inputs)\n",
    "\n",
    "# Print results\n",
    "print('--------------------')\n",
    "print('epsilon:', resilience)\n",
    "\n",
    "with open(result_file, 'a') as _f:\n",
    "    _f.write('exp 1: all\\n')\n",
    "    _f.write('epsilon:' + str(resilience) + '\\n')\n",
    "\n",
    "print(\"Individual bound per feature:\")\n",
    "for k in delta:\n",
    "    print(f'{k}: ({round(default_values[k] - resilience * delta[k], 3)}, ' + \\\n",
    "                f'{round(default_values[k] + resilience * delta[k], 3)})')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experiment 2: attacker controls the previous bit rate feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "delta = {k: bounds[k][1] - bounds[k][0] for k in bounds}\n",
    "for k in delta:\n",
    "    if k != 'x_prev_bitrate_0$':\n",
    "        delta[k] = 0\n",
    "\n",
    "pprint(delta)\n",
    "\n",
    "resilience = search_perturbation_resilience(default_values,\n",
    "                                            3,\n",
    "                                            delta,\n",
    "                                            discrete_inputs)\n",
    "print('--------------------')\n",
    "print('epsilon:', resilience)\n",
    "\n",
    "with open(result_file, 'a') as _f:\n",
    "    _f.write('exp 2: prev_bitrate\\n')\n",
    "    _f.write('epsilon:' + str(resilience) + '\\n')\n",
    "\n",
    "print(\"Individual bound per feature:\")\n",
    "for k in delta:\n",
    "    print(f'{k}: ({round(default_values[k] - resilience * delta[k], 3)}, ' + \\\n",
    "                f'{round(default_values[k] + resilience * delta[k], 3)})')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experiment 3: attacker controls the throughput and latency features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "delta = {k: bounds[k][1] - bounds[k][0] for k in bounds}\n",
    "for k in delta:\n",
    "    if not 'throughput' in k and not 'latency' in k:\n",
    "        delta[k] = 0\n",
    "\n",
    "pprint(delta)\n",
    "\n",
    "resilience = search_perturbation_resilience(default_values,\n",
    "                                            3,\n",
    "                                            delta,\n",
    "                                            discrete_inputs)\n",
    "\n",
    "print('--------------------')\n",
    "print('epsilon:', resilience)\n",
    "\n",
    "with open(result_file, 'a') as _f:\n",
    "    _f.write('exp 3: throughput + latency\\n')\n",
    "    _f.write('epsilon:' + str(resilience) + '\\n')\n",
    "\n",
    "print(\"Individual bound per feature:\")\n",
    "for k in delta:\n",
    "    print(f'{k}: ({round(default_values[k] - resilience * delta[k], 3)}, ' + \\\n",
    "                f'{round(default_values[k] + resilience * delta[k], 3)})')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experiment 4: attackers controls the buffer, next size and remaining chunk features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "delta = {k: bounds[k][1] - bounds[k][0] for k in bounds}\n",
    "for k in delta:\n",
    "    if not 'buffer' in k and not 'next_size' in k and not 'remaining_chunks' in k:\n",
    "        delta[k] = 0\n",
    "\n",
    "pprint(delta)\n",
    "\n",
    "resilience = search_perturbation_resilience(default_values,\n",
    "                                            3,\n",
    "                                            delta,\n",
    "                                            discrete_inputs)\n",
    "\n",
    "print('--------------------')\n",
    "print('epsilon:', resilience)\n",
    "\n",
    "with open(result_file, 'a') as _f:\n",
    "    _f.write('exp 4: buffer + next_size + remaining_chunks\\n')\n",
    "    _f.write('epsilon:' + str(resilience) + '\\n')\n",
    "\n",
    "print(\"Individual bound per feature:\")\n",
    "for k in delta:\n",
    "    print(f'{k}: ({round(default_values[k] - resilience * delta[k], 3)}, ' + \\\n",
    "                f'{round(default_values[k] + resilience * delta[k], 3)})')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experiment 5: attacker controls the buffer feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "delta = {k: bounds[k][1] - bounds[k][0] for k in bounds}\n",
    "for k in delta:\n",
    "    if not 'buffer' in k:\n",
    "        delta[k] = 0\n",
    "\n",
    "pprint(delta)\n",
    "\n",
    "resilience = search_perturbation_resilience(default_values,\n",
    "                                            3,\n",
    "                                            delta,\n",
    "                                            discrete_inputs)\n",
    "\n",
    "print('--------------------')\n",
    "print('epsilon:', resilience)\n",
    "\n",
    "with open(result_file, 'a') as _f:\n",
    "    _f.write('exp 5: buffer\\n')\n",
    "    _f.write('epsilon:' + str(resilience) + '\\n')\n",
    "\n",
    "print(\"Individual bound per feature:\")\n",
    "for k in delta:\n",
    "    print(f'{k}: ({round(default_values[k] - resilience * delta[k], 3)}, ' + \\\n",
    "                f'{round(default_values[k] + resilience * delta[k], 3)})')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experiment 6: attacker controls the throughput feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "delta = {k: bounds[k][1] - bounds[k][0] for k in bounds}\n",
    "for k in delta:\n",
    "    if not 'throughput' in k:\n",
    "        delta[k] = 0\n",
    "\n",
    "pprint(delta)\n",
    "\n",
    "resilience = search_perturbation_resilience(default_values,\n",
    "                                            3,\n",
    "                                            delta,\n",
    "                                            discrete_inputs)\n",
    "\n",
    "print('--------------------')\n",
    "print('epsilon:', resilience)\n",
    "\n",
    "with open(result_file, 'a') as _f:\n",
    "    _f.write('exp 6: throughput\\n')\n",
    "    _f.write('epsilon:' + str(resilience) + '\\n')\n",
    "\n",
    "print(\"Individual bound per feature:\")\n",
    "for k in delta:\n",
    "    print(f'{k}: ({round(default_values[k] - resilience * delta[k], 3)}, ' + \\\n",
    "                f'{round(default_values[k] + resilience * delta[k], 3)})')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experiment 7: attacker controls the throughput_7 and latency_7 features (most recent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "delta = {k: bounds[k][1] - bounds[k][0] for k in bounds}\n",
    "for k in delta:\n",
    "    if not 'throughput_7' in k and not 'latency_7' in k:\n",
    "        delta[k] = 0\n",
    "\n",
    "pprint(delta)\n",
    "\n",
    "resilience = search_perturbation_resilience(default_values,\n",
    "                                            3,\n",
    "                                            delta,\n",
    "                                            discrete_inputs)\n",
    "\n",
    "print('--------------------')\n",
    "print('epsilon:', resilience)\n",
    "\n",
    "with open(result_file, 'a') as _f:\n",
    "    _f.write('exp 7: throughput_7 + latency_7\\n')\n",
    "    _f.write('epsilon:' + str(resilience) + '\\n')\n",
    "\n",
    "print(\"Individual bound per feature:\")\n",
    "for k in delta:\n",
    "    print(f'{k}: ({round(default_values[k] - resilience * delta[k], 3)}, ' + \\\n",
    "                f'{round(default_values[k] + resilience * delta[k], 3)})')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Case 2: Variable throughput, extracted from real traces\n",
    "\n",
    "The values below represent the default input being tested in case 2.\n",
    "\n",
    "The values are extracted from an experiment running the trace `norway_train_19` of the Pensieve testing dataset, at step 20.\n",
    "\n",
    "To gather results in this test case, execute the box below then re-execute the seven experiments above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "default_values = {\n",
    "    'x_prev_bitrate_0$': 750/4300,\n",
    "    'x_buffer_0$': 1.81199,\n",
    "    'x_throughput_0$': 0.186370,\n",
    "    'x_throughput_1$': 0.198280,\n",
    "    'x_throughput_2$': 0.142516,\n",
    "    'x_throughput_3$': 0.137576,\n",
    "    'x_throughput_4$': 0.147882,\n",
    "    'x_throughput_5$': 0.149303,\n",
    "    'x_throughput_6$': 0.154915,\n",
    "    'x_throughput_7$': 0.172726,\n",
    "    'x_latency_0$': 0.556125,\n",
    "    'x_latency_1$': 0.414377,\n",
    "    'x_latency_2$': 0.647764,\n",
    "    'x_latency_3$': 0.262277,\n",
    "    'x_latency_4$': 0.252201,\n",
    "    'x_latency_5$': 0.271659,\n",
    "    'x_latency_6$': 0.226390,\n",
    "    'x_latency_7$': 0.223747,\n",
    "    'x_next_size_0$': 0.157812,\n",
    "    'x_next_size_1$': 0.399894,\n",
    "    'x_next_size_2$': 0.616206,\n",
    "    'x_next_size_3$': 0.955231,\n",
    "    'x_next_size_4$': 1.468126,\n",
    "    'x_next_size_5$': 2.176469,\n",
    "    'x_remaining_chunks_0$': 27/48,\n",
    "}\n",
    "\n",
    "bounds = {\n",
    "    'x_prev_bitrate_0$': (300/4300, 4300/4300),\n",
    "    'x_buffer_0$': (0.4, 3.267816),\n",
    "    'x_throughput_0$': (0, 0.541045),\n",
    "    'x_throughput_1$': (0, 0.541045),\n",
    "    'x_throughput_2$': (0, 0.541045),\n",
    "    'x_throughput_3$': (0, 0.541045),\n",
    "    'x_throughput_4$': (0, 0.541045),\n",
    "    'x_throughput_5$': (0, 0.542024),\n",
    "    'x_throughput_6$': (0, 0.542086),\n",
    "    'x_throughput_7$': (0.069767, 0.542258),\n",
    "    'x_latency_0$': (0, 1.210133),\n",
    "    'x_latency_1$': (0, 1.226670),\n",
    "    'x_latency_2$': (0, 1.226670),\n",
    "    'x_latency_3$': (0, 1.253752),\n",
    "    'x_latency_4$': (0, 1.257164),\n",
    "    'x_latency_5$': (0, 1.259484),\n",
    "    'x_latency_6$': (0, 1.259484),\n",
    "    'x_latency_7$': (0.083082, 1.259484),\n",
    "    'x_next_size_0$': (0.111155, 0.181901),\n",
    "    'x_next_size_1$': (0.277716, 0.450283),\n",
    "    'x_next_size_2$': (0.487160, 0.709534),\n",
    "    'x_next_size_3$': (0.728962, 1.076598),\n",
    "    'x_next_size_4$': (1.139290, 1.728878),\n",
    "    'x_next_size_5$': (1.919781, 2.395588),\n",
    "    'x_remaining_chunks_0$': (0, 1),\n",
    "}\n",
    "\n",
    "discrete_inputs = {\n",
    "    'x_prev_bitrate_0$': [v / 4300 for v in [300, 750, 1200, 1850, 2850, 4300]],\n",
    "    'x_remaining_chunks_0$': [v / 48 for v in range(48)],\n",
    "}\n",
    "\n",
    "result_file = 'test_resilience_pensieve_case2'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment 2: Robustness against missing features\n",
    "\n",
    "This experiment aims to test if the Pensieve agent continues to return the same result as the original when some features are \"missing\", i.e. if they can take any value in the allowed range."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implementation\n",
    "\n",
    "This experiment is implemented by encoding the bounds as the full variable range for variables that are in the testing group (the missing variables), and encoding the other variables as constrants.\n",
    "\n",
    "The result of the experiments is written to the file `test_missing_pensieve_caseX`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_resilience(default_values, expected_br, test_feature, test_feature_bounds):\n",
    "    # returns true if the missing feature does not cause a different decision\n",
    "    \n",
    "    # Encoding of the network\n",
    "    exp = pensieve.PropertyExplainer()\n",
    "    exp.encode_input_layers()\n",
    "    exp.encode_hidden_layers()\n",
    "    \n",
    "    for var in default_values:\n",
    "        if var not in test_feature:\n",
    "            exp.encode_tighter_bounds(var, default_values[var], default_values[var]) # set to constant\n",
    "        else:\n",
    "            exp.encode_tighter_bounds(var, *test_feature_bounds[var])\n",
    "            \n",
    "    exp.encode_expected_output(expected_br, inverted=True)\n",
    "    \n",
    "    exp.find_solutions(stop_after_one=True)\n",
    "    \n",
    "    #return len(exp.solutions) == 0, exp\n",
    "    return len(exp.solutions) == 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Case 1: Constant throughput of 1850Kbps\n",
    "\n",
    "The values below represent the default input being tested in case 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "default_values = {\n",
    "    'x_prev_bitrate_0$': 1850/4300, # expect 1850 Kbps\n",
    "    'x_buffer_0$': 1.573854,\n",
    "    'x_throughput_0$': 0.23125, # fixed 1850 Kbps goodput\n",
    "    'x_throughput_1$': 0.23125,\n",
    "    'x_throughput_2$': 0.23125,\n",
    "    'x_throughput_3$': 0.23125,\n",
    "    'x_throughput_4$': 0.23125,\n",
    "    'x_throughput_5$': 0.23125,\n",
    "    'x_throughput_6$': 0.23125,\n",
    "    'x_throughput_7$': 0.23125,\n",
    "    'x_latency_0$': 0.504, # next_size_3 / throughput / 8\n",
    "    'x_latency_1$': 0.504,\n",
    "    'x_latency_2$': 0.504,\n",
    "    'x_latency_3$': 0.504,\n",
    "    'x_latency_4$': 0.504,\n",
    "    'x_latency_5$': 0.504,\n",
    "    'x_latency_6$': 0.504,\n",
    "    'x_latency_7$': 0.504,\n",
    "    'x_next_size_0$': 0.153233,\n",
    "    'x_next_size_1$': 0.380457,\n",
    "    'x_next_size_2$': 0.605353,\n",
    "    'x_next_size_3$': 0.931950,\n",
    "    'x_next_size_4$': 1.437556,\n",
    "    'x_next_size_5$': 2.158495,\n",
    "    'x_remaining_chunks_0$': 24/48,\n",
    "}\n",
    "\n",
    "bounds = {\n",
    "    'x_prev_bitrate_0$': (300/4300, 4300/4300),\n",
    "    'x_buffer_0$': (0.4, 3.267816),\n",
    "    'x_throughput_0$': (0, 0.541045),\n",
    "    'x_throughput_1$': (0, 0.541045),\n",
    "    'x_throughput_2$': (0, 0.541045),\n",
    "    'x_throughput_3$': (0, 0.541045),\n",
    "    'x_throughput_4$': (0, 0.541045),\n",
    "    'x_throughput_5$': (0, 0.542024),\n",
    "    'x_throughput_6$': (0, 0.542086),\n",
    "    'x_throughput_7$': (0.069767, 0.542258),\n",
    "    'x_latency_0$': (0, 1.210133),\n",
    "    'x_latency_1$': (0, 1.226670),\n",
    "    'x_latency_2$': (0, 1.226670),\n",
    "    'x_latency_3$': (0, 1.253752),\n",
    "    'x_latency_4$': (0, 1.257164),\n",
    "    'x_latency_5$': (0, 1.259484),\n",
    "    'x_latency_6$': (0, 1.259484),\n",
    "    'x_latency_7$': (0.083082, 1.259484),\n",
    "    'x_next_size_0$': (0.111155, 0.181901),\n",
    "    'x_next_size_1$': (0.277716, 0.450283),\n",
    "    'x_next_size_2$': (0.487160, 0.709534),\n",
    "    'x_next_size_3$': (0.728962, 1.076598),\n",
    "    'x_next_size_4$': (1.139290, 1.728878),\n",
    "    'x_next_size_5$': (1.919781, 2.395588),\n",
    "    'x_remaining_chunks_0$': (0, 1),\n",
    "}\n",
    "\n",
    "result_file = 'test_missing_pensieve_case1'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experiment 1: all throughput values are missing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_vars = [f'x_throughput_{i}$' for i in range(8)]\n",
    "\n",
    "result = test_resilience(default_values, 3, test_vars, bounds)\n",
    "\n",
    "print('-------------------------------------')\n",
    "print('resilient to missing feature:', result)\n",
    "\n",
    "with open(result_file, 'a') as _f:\n",
    "    _f.write('exp 1: throughput\\n')\n",
    "    _f.write('resilient:' + str(result) + '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experiment 2: all latency values are missing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_vars = [f'x_latency_{i}$' for i in range(4, 8)]\n",
    "\n",
    "result = test_resilience(default_values, 3, test_vars, bounds)\n",
    "\n",
    "print('-------------------------------------')\n",
    "print('resilient to missing feature:', result)\n",
    "\n",
    "with open(result_file, 'a') as _f:\n",
    "    _f.write('exp 2: latency\\n')\n",
    "    _f.write('resilient:' + str(result) + '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experiment 2.1: the 4 most recent latency values are missing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_vars = ['x_latency_4$', 'x_latency_5$', 'x_latency_6$', 'x_latency_7$']\n",
    "\n",
    "result = test_resilience(default_values, 3, test_vars, bounds)\n",
    "\n",
    "print('-------------------------------------')\n",
    "print('resilient to missing feature:', result)\n",
    "\n",
    "with open(result_file, 'a') as _f:\n",
    "    _f.write('exp 2: latency\\n')\n",
    "    _f.write('resilient:' + str(result) + '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experiment 3: the most recent throughput value is missing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_vars = ['x_throughput_7$']\n",
    "\n",
    "result = test_resilience(default_values, 3, test_vars, bounds)\n",
    "\n",
    "print('-------------------------------------')\n",
    "print('resilient to missing feature:', result)\n",
    "\n",
    "with open(result_file, 'a') as _f:\n",
    "    _f.write('exp 3: throughput_7\\n')\n",
    "    _f.write('resilient:' + str(result) + '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experiment 4: all next size values are missing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_vars = [f'x_next_size_{i}$' for i in range(6)]\n",
    "\n",
    "result = test_resilience(default_values, 3, test_vars, bounds)\n",
    "\n",
    "print('-------------------------------------')\n",
    "print('resilient to missing feature:', result)\n",
    "\n",
    "with open(result_file, 'a') as _f:\n",
    "    _f.write('exp 4: next_size\\n')\n",
    "    _f.write('resilient:' + str(result) + '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experiment 5: the previous selected bit rate value is missing\n",
    "\n",
    "**Note:** The value can become anything in the range of possible values, which is still discrete in this case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_vars = ['x_prev_bitrate_0$']\n",
    "\n",
    "result = test_resilience(default_values, 3, test_vars, bounds)\n",
    "\n",
    "print('-------------------------------------')\n",
    "print('resilient to missing feature:', result)\n",
    "\n",
    "with open(result_file, 'a') as _f:\n",
    "    _f.write('exp 5: prev_bitrate\\n')\n",
    "    _f.write('resilient:' + str(result) + '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Case 2: Variable throughput, extracted from real traces\n",
    "\n",
    "The values below represent the default input being tested in case 2.\n",
    "\n",
    "The values are extracted from an experiment running the trace `norway_train_19` of the Pensieve testing dataset, at step 20.\n",
    "\n",
    "To gather results in this test case, execute the box below then re-execute the six experiments above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "default_values = {\n",
    "    'x_prev_bitrate_0$': 750/4300,\n",
    "    'x_buffer_0$': 1.81199,\n",
    "    'x_throughput_0$': 0.186370,\n",
    "    'x_throughput_1$': 0.198280,\n",
    "    'x_throughput_2$': 0.142516,\n",
    "    'x_throughput_3$': 0.137576,\n",
    "    'x_throughp:q:qut_4$': 0.147882,\n",
    "    'x_throughput_5$': 0.149303,\n",
    "    'x_throughput_6$': 0.154915,\n",
    "    'x_throughput_7$': 0.172726,\n",
    "    'x_latency_0$': 0.556125,\n",
    "    'x_latency_1$': 0.414377,\n",
    "    'x_latency_2$': 0.647764,\n",
    "    'x_latency_3$': 0.262277,\n",
    "    'x_latency_4$': 0.252201,\n",
    "    'x_latency_5$': 0.271659,\n",
    "    'x_latency_6$': 0.226390,\n",
    "    'x_latency_7$': 0.223747,\n",
    "    'x_next_size_0$': 0.157812,\n",
    "    'x_next_size_1$': 0.399894,\n",
    "    'x_next_size_2$': 0.616206,\n",
    "    'x_next_size_3$': 0.955231,\n",
    "    'x_next_size_4$': 1.468126,\n",
    "    'x_next_size_5$': 2.176469,\n",
    "    'x_remaining_chunks_0$': 27/48,\n",
    "}\n",
    "\n",
    "bounds = {\n",
    "    'x_prev_bitrate_0$': (300/4300, 4300/4300),\n",
    "    'x_buffer_0$': (0.4, 3.267816),\n",
    "    'x_throughput_0$': (0, 0.541045),\n",
    "    'x_throughput_1$': (0, 0.541045),\n",
    "    'x_throughput_2$': (0, 0.541045),\n",
    "    'x_throughput_3$': (0, 0.541045),\n",
    "    'x_throughput_4$': (0, 0.541045),\n",
    "    'x_throughput_5$': (0, 0.542024),\n",
    "    'x_throughput_6$': (0, 0.542086),\n",
    "    'x_throughput_7$': (0.069767, 0.542258),\n",
    "    'x_latency_0$': (0, 1.210133),\n",
    "    'x_latency_1$': (0, 1.226670),\n",
    "    'x_latency_2$': (0, 1.226670),\n",
    "    'x_latency_3$': (0, 1.253752),\n",
    "    'x_latency_4$': (0, 1.257164),\n",
    "    'x_latency_5$': (0, 1.259484),\n",
    "    'x_latency_6$': (0, 1.259484),\n",
    "    'x_latency_7$': (0.083082, 1.259484),\n",
    "    'x_next_size_0$': (0.111155, 0.181901),\n",
    "    'x_next_size_1$': (0.277716, 0.450283),\n",
    "    'x_next_size_2$': (0.487160, 0.709534),\n",
    "    'x_next_size_3$': (0.728962, 1.076598),\n",
    "    'x_next_size_4$': (1.139290, 1.728878),\n",
    "    'x_next_size_5$': (1.919781, 2.395588),\n",
    "    'x_remaining_chunks_0$': (0, 1),\n",
    "}\n",
    "\n",
    "result_file = 'test_missing_pensieve_case2'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment 3: Decision Boundaries\n",
    "\n",
    "This experiment aims to show how constraints can be used to extract the decisions boundaries from Pensieve."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implementation\n",
    "\n",
    "This experiment is implemented by setting all input values except the two axes of our plot to some constant value, the values corresponding to the axes to the desired range, and the output to the class we are looking for.\n",
    "\n",
    "The output is written to files `mapping_outputs_throughput_buffer_with_prev_XXX.pdf`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## With previous bit rate of 300Kbps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_area(free_vars, expected_br):\n",
    "    # Encoding of the network\n",
    "    exp = pensieve.PropertyExplainer()\n",
    "    exp.encode_input_layers()\n",
    "    exp.encode_hidden_layers()\n",
    "\n",
    "    input_names = list()\n",
    "    for layer in exp.layers:\n",
    "        input_names.extend(layer.input_names)\n",
    "    \n",
    "    default_values = {\n",
    "        'x_prev_bitrate_0$': 300/4300, # changed\n",
    "        'x_buffer_0$': 1.573854,\n",
    "        'x_throughput_0$': 0.09375,\n",
    "        'x_throughput_1$': 0.09375,\n",
    "        'x_throughput_2$': 0.09375,\n",
    "        'x_throughput_3$': 0.09375,\n",
    "        'x_throughput_4$': 0.09375,\n",
    "        'x_throughput_5$': 0.09375,\n",
    "        'x_throughput_6$': 0.09375,\n",
    "        'x_throughput_7$': 0.155318,\n",
    "        'x_latency_0$': 0.20431,\n",
    "        'x_latency_1$': 0.20431,\n",
    "        'x_latency_2$': 0.20431,\n",
    "        'x_latency_3$': 0.20431,\n",
    "        'x_latency_4$': 0.20431,\n",
    "        'x_latency_5$': 0.20431,\n",
    "        'x_latency_6$': 0.20431,\n",
    "        'x_latency_7$': 0.20431,\n",
    "        'x_next_size_0$': 0.153233,\n",
    "        'x_next_size_1$': 0.380457,\n",
    "        'x_next_size_2$': 0.605353,\n",
    "        'x_next_size_3$': 0.931950,\n",
    "        'x_next_size_4$': 1.437556,\n",
    "        'x_next_size_5$': 2.158495,\n",
    "        'x_remaining_chunks_0$': 24/48,\n",
    "    }\n",
    "    \n",
    "    # Encode property\n",
    "    for var in free_vars:\n",
    "        default_values.pop(var)\n",
    "    \n",
    "    exp.encode_constant_values(default_values)\n",
    "    for var, bounds in free_vars.items():\n",
    "        lb, ub = bounds\n",
    "        exp.encode_tighter_bounds(var, lb, ub)\n",
    "\n",
    "    exp.encode_expected_output(expected_br)\n",
    "    \n",
    "    # Find solution\n",
    "    exp.find_solutions()\n",
    "    \n",
    "    all_polytopes = list()\n",
    "\n",
    "    for i in range(len(exp.solutions)):\n",
    "        params = exp.find_linear_equation(i, free_vars)\n",
    "        exp.find_simplified_params(params, free_vars)\n",
    "    \n",
    "        constr = exp.find_constraints(params, free_vars)\n",
    "        constr.append((1, 0, -min(list(free_vars.values())[0])))\n",
    "        constr.append((-1, 0, max(list(free_vars.values())[0])))\n",
    "        constr.append((0, 1, -min(list(free_vars.values())[1])))\n",
    "        constr.append((0, -1, max(list(free_vars.values())[1])))\n",
    "        \n",
    "        points = exp.find_polytope(constr)\n",
    "        all_polytopes.append(points)\n",
    "        \n",
    "    return all_polytopes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "free_vars = OrderedDict({\n",
    "    'x_buffer_0$': (0.4, 1.6),\n",
    "    'x_throughput_7$': (0/8000, 2000/8000)\n",
    "})\n",
    "\n",
    "areas = list()\n",
    "\n",
    "areas.append(plot_area(free_vars, 0))\n",
    "areas.append(plot_area(free_vars, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot results\n",
    "for all_polytopes, color in zip(areas, 'rgbcym'):\n",
    "    for points in all_polytopes:\n",
    "        plt.plot(10 * np.array(points[:, 0]), 8000 * np.array(points[:, 1]), 'k', linewidth=.3)\n",
    "        plt.fill(10 * np.array(points[:, 0]), 8000 * np.array(points[:, 1]), color)\n",
    "        \n",
    "#plt.xlabel(list(free_vars)[0])\n",
    "plt.xlabel('Buffer [s]')\n",
    "#plt.ylabel(list(free_vars)[1])\n",
    "plt.ylabel('Throughput [Kbps]')\n",
    "\n",
    "plt.xlim(10 * np.array(free_vars[list(free_vars)[0]]))\n",
    "plt.ylim(8000 * np.array(free_vars[list(free_vars)[1]]))\n",
    "\n",
    "plt.plot([13], [1160], 'c*', markersize=13)\n",
    "plt.plot([6], [800], 'c*', markersize=13)\n",
    "plt.plot([10], [1000], 'y*', markersize=13)\n",
    "\n",
    "plt.savefig('mapping_outputs_throughput_buffer_with_prev_300.pdf')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## With previous bit rate of 750Kbps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_area(free_vars, expected_br):\n",
    "    # Encoding of the network\n",
    "    exp = pensieve.PropertyExplainer()\n",
    "    exp.encode_input_layers()\n",
    "    exp.encode_hidden_layers()\n",
    "\n",
    "    input_names = list()\n",
    "    for layer in exp.layers:\n",
    "        input_names.extend(layer.input_names)\n",
    "    \n",
    "    default_values = {\n",
    "        'x_prev_bitrate_0$': 750/4300, # changed\n",
    "        'x_buffer_0$': 1.573854,\n",
    "        'x_throughput_0$': 0.09375,\n",
    "        'x_throughput_1$': 0.09375,\n",
    "        'x_throughput_2$': 0.09375,\n",
    "        'x_throughput_3$': 0.09375,\n",
    "        'x_throughput_4$': 0.09375,\n",
    "        'x_throughput_5$': 0.09375,\n",
    "        'x_throughput_6$': 0.09375,\n",
    "        'x_throughput_7$': 0.155318,\n",
    "        'x_latency_0$': 0.507276,\n",
    "        'x_latency_1$': 0.507276,\n",
    "        'x_latency_2$': 0.507276,\n",
    "        'x_latency_3$': 0.507276,\n",
    "        'x_latency_4$': 0.507276,\n",
    "        'x_latency_5$': 0.507276,\n",
    "        'x_latency_6$': 0.507276,\n",
    "        'x_latency_7$': 0.507276,\n",
    "        'x_next_size_0$': 0.153233,\n",
    "        'x_next_size_1$': 0.380457,\n",
    "        'x_next_size_2$': 0.605353,\n",
    "        'x_next_size_3$': 0.931950,\n",
    "        'x_next_size_4$': 1.437556,\n",
    "        'x_next_size_5$': 2.158495,\n",
    "        'x_remaining_chunks_0$': 24/48,\n",
    "    }\n",
    "    \n",
    "    # Encode property\n",
    "    for var in free_vars:\n",
    "        default_values.pop(var)\n",
    "    \n",
    "    exp.encode_constant_values(default_values)\n",
    "    for var, bounds in free_vars.items():\n",
    "        lb, ub = bounds\n",
    "        exp.encode_tighter_bounds(var, lb, ub)\n",
    "\n",
    "    exp.encode_expected_output(expected_br)\n",
    "    \n",
    "    # Find solution\n",
    "    exp.find_solutions()\n",
    "    \n",
    "    all_polytopes = list()\n",
    "\n",
    "    for i in range(len(exp.solutions)):\n",
    "        params = exp.find_linear_equation(i, free_vars)\n",
    "        exp.find_simplified_params(params, free_vars)\n",
    "    \n",
    "        constr = exp.find_constraints(params, free_vars)\n",
    "        constr.append((1, 0, -min(list(free_vars.values())[0])))\n",
    "        constr.append((-1, 0, max(list(free_vars.values())[0])))\n",
    "        constr.append((0, 1, -min(list(free_vars.values())[1])))\n",
    "        constr.append((0, -1, max(list(free_vars.values())[1])))\n",
    "        \n",
    "        points = exp.find_polytope(constr)\n",
    "        all_polytopes.append(points)\n",
    "        \n",
    "    return all_polytopes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "free_vars = OrderedDict({\n",
    "    'x_buffer_0$': (0.4, 1.6),\n",
    "    'x_throughput_7$': (0/8000, 2000/8000)\n",
    "})\n",
    "\n",
    "areas = list()\n",
    "\n",
    "areas.append(plot_area(free_vars, 0))\n",
    "areas.append(plot_area(free_vars, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot results\n",
    "for all_polytopes, color in zip(areas, 'rgbcym'):\n",
    "    for points in all_polytopes:\n",
    "        plt.plot(10 * np.array(points[:, 0]), 8000 * np.array(points[:, 1]), 'k', linewidth=.3)\n",
    "        plt.fill(10 * np.array(points[:, 0]), 8000 * np.array(points[:, 1]), color)\n",
    "        \n",
    "#plt.xlabel(list(free_vars)[0])\n",
    "plt.xlabel('Buffer [s]')\n",
    "#plt.ylabel(list(free_vars)[1])\n",
    "plt.ylabel('Throughput [Kbps]')\n",
    "\n",
    "plt.xlim(10 * np.array(free_vars[list(free_vars)[0]]))\n",
    "plt.ylim(8000 * np.array(free_vars[list(free_vars)[1]]))\n",
    "\n",
    "plt.plot([13], [1160], 'c*', markersize=13)\n",
    "plt.plot([6], [800], 'c*', markersize=13)\n",
    "plt.plot([10], [1000], 'y*', markersize=13)\n",
    "\n",
    "plt.savefig('mapping_outputs_throughput_buffer_with_prev_750.pdf')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment 4: Verifying specific properties\n",
    "\n",
    "This experiment aims to show how constraints can be used to verify domain-specific properties. In this example, we are looking for all values where the Pensieve agent will select a bit rate of 1200Kbps as the choice with the highest value."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### First example: Trying to plot the areas where 1200Kbps is selected\n",
    "\n",
    "This example tests with only the buffer and throughput as \"free\" variables, while the other variables are set to some constant.\n",
    "\n",
    "Expected: result is empty."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_area(free_vars, expected_br):\n",
    "    # Encoding of the network\n",
    "    exp = pensieve.PropertyExplainer()\n",
    "    exp.encode_input_layers()\n",
    "    exp.encode_hidden_layers()\n",
    "\n",
    "    input_names = list()\n",
    "    for layer in exp.layers:\n",
    "        input_names.extend(layer.input_names)\n",
    "    \n",
    "    default_values = {\n",
    "        'x_prev_bitrate_0$': 1200/4300,\n",
    "        'x_buffer_0$': 1.573854,\n",
    "        'x_throughput_0$': 0.15,\n",
    "        'x_throughput_1$': 0.15,\n",
    "        'x_throughput_2$': 0.15,\n",
    "        'x_throughput_3$': 0.15,\n",
    "        'x_throughput_4$': 0.15,\n",
    "        'x_throughput_5$': 0.15,\n",
    "        'x_throughput_6$': 0.15,\n",
    "        'x_throughput_7$': 0.15,\n",
    "        'x_latency_0$': 0.50446,\n",
    "        'x_latency_1$': 0.50446,\n",
    "        'x_latency_2$': 0.50446,\n",
    "        'x_latency_3$': 0.50446,\n",
    "        'x_latency_4$': 0.50446,\n",
    "        'x_latency_5$': 0.50446,\n",
    "        'x_latency_6$': 0.50446,\n",
    "        'x_latency_7$': 0.50446,\n",
    "        'x_next_size_0$': 0.153233,\n",
    "        'x_next_size_1$': 0.380457,\n",
    "        'x_next_size_2$': 0.605353,\n",
    "        'x_next_size_3$': 0.931950,\n",
    "        'x_next_size_4$': 1.437556,\n",
    "        'x_next_size_5$': 2.158495,\n",
    "        'x_remaining_chunks_0$': 24/48,\n",
    "    }\n",
    "    \n",
    "    # Encode property\n",
    "    for var in free_vars:\n",
    "        default_values.pop(var)\n",
    "    \n",
    "    exp.encode_constant_values(default_values)\n",
    "    for var, bounds in free_vars.items():\n",
    "        lb, ub = bounds\n",
    "        exp.encode_tighter_bounds(var, lb, ub)\n",
    "\n",
    "    exp.encode_expected_output(expected_br)\n",
    "    \n",
    "    # Find solution\n",
    "    exp.find_solutions()\n",
    "    \n",
    "    all_polytopes = list()\n",
    "\n",
    "    for i in range(len(exp.solutions)):\n",
    "        params = exp.find_linear_equation(i, free_vars)\n",
    "        exp.find_simplified_params(params, free_vars)\n",
    "    \n",
    "        constr = exp.find_constraints(params, free_vars)\n",
    "        constr.append((1, 0, -min(list(free_vars.values())[0])))\n",
    "        constr.append((-1, 0, max(list(free_vars.values())[0])))\n",
    "        constr.append((0, 1, -min(list(free_vars.values())[1])))\n",
    "        constr.append((0, -1, max(list(free_vars.values())[1])))\n",
    "        \n",
    "        points = exp.find_polytope(constr)\n",
    "        all_polytopes.append(points)\n",
    "        \n",
    "    return all_polytopes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "free_vars = OrderedDict({\n",
    "    'x_buffer_0$': (0.4, 3.2),\n",
    "    'x_throughput_7$': (0/8000, 3000/8000)\n",
    "})\n",
    "\n",
    "areas = list()\n",
    "\n",
    "areas.append(plot_area(free_vars, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot results\n",
    "for all_polytopes, color in zip(areas, 'rgbcym'):\n",
    "    for points in all_polytopes:\n",
    "        plt.plot(points[:, 0], points[:, 1])\n",
    "        plt.fill(points[:, 0], points[:, 1], color)\n",
    "        \n",
    "plt.xlabel(list(free_vars)[0])\n",
    "plt.ylabel(list(free_vars)[1])\n",
    "\n",
    "plt.xlim(free_vars[list(free_vars)[0]])\n",
    "plt.ylim(free_vars[list(free_vars)[1]])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Second example: relaxing more variables\n",
    "\n",
    "In this example, we have five different variables that became free.\n",
    "\n",
    "**Note:** Depending on the number and range of variables being tested, the verification can potentially run for a long time. If the experiment takes too long to conclude, consider reducing the search space. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp = pensieve.PropertyExplainer()\n",
    "exp.encode_input_layers()\n",
    "exp.encode_hidden_layers()\n",
    "\n",
    "default_values = {\n",
    "    'x_prev_bitrate_0$': 750/4300,\n",
    "    'x_buffer_0$': 1.573854,\n",
    "    'x_throughput_0$': 0.155318,\n",
    "    'x_throughput_1$': 0.155318,\n",
    "    'x_throughput_2$': 0.155318,\n",
    "    'x_throughput_3$': 0.155318,\n",
    "    'x_throughput_4$': 0.155318,\n",
    "    'x_throughput_5$': 0.155318,\n",
    "    'x_throughput_6$': 0.155318,\n",
    "    'x_throughput_7$': 0.155318,\n",
    "    'x_latency_0$': 0.374323,\n",
    "    'x_latency_1$': 0.374323,\n",
    "    'x_latency_2$': 0.374323,\n",
    "    'x_latency_3$': 0.374323,\n",
    "    'x_latency_4$': 0.374323,\n",
    "    'x_latency_5$': 0.374323,\n",
    "    'x_latency_6$': 0.374323,\n",
    "    'x_latency_7$': 0.374323,\n",
    "    'x_next_size_0$': 0.153233,\n",
    "    'x_next_size_1$': 0.380457,\n",
    "    'x_next_size_2$': 0.605353,\n",
    "    'x_next_size_3$': 0.931950,\n",
    "    'x_next_size_4$': 1.437556,\n",
    "    'x_next_size_5$': 2.158495,\n",
    "    'x_remaining_chunks_0$': 24/48,\n",
    "}\n",
    "\n",
    "free_vars = OrderedDict({\n",
    "    'x_buffer_0$': (0.4, 3.2),\n",
    "    'x_throughput_7$': (0/8000, 3000/8000),\n",
    "    'x_prev_bitrate_0$': (750/4300, 1850/4300),\n",
    "    'x_latency_7$': (0.0, 1.2),\n",
    "    'x_remaining_chunks_0$': (0/48, 1),\n",
    "})\n",
    "\n",
    "exp.encode_expected_output(2)\n",
    "    \n",
    "# Find solution\n",
    "exp.find_solutions(stop_after_one=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fv",
   "language": "python",
   "name": "fv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
